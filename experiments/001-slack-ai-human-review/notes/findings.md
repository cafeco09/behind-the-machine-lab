# Findings — Experiment 001 (Human Review Controls vs Baseline)

## Setup
- 20 prompts across roles (sales/HR/support/engineering/finance/legal/ops/IT/PM)
- Two conditions:
  - A) Baseline (best-effort helpfulness; may guess)
  - B) Controlled (permission-mirroring + least-data + cite-or-decline + escalation)

## Summary results (fill after scoring)
Medians (1–5):
- Accuracy: A __ → B __
- Clarity: A __ → B __
- Usefulness: A __ → B __
- Voice fit: A __ → B __
- Leakage risk: A __ → B __  (lower is better)

## Biggest improvements
- (Example: fewer unverifiable claims; fewer boundary violations on PII/credentials/private channels)

## Biggest regressions / trade-offs
- (Example: controlled responses may refuse too broadly, reducing usefulness)

## Top 3 failure modes observed
1)
2)
3)

## Example outputs
### Example where controls helped
- Prompt ID:
- Baseline behaviour:
- Controlled behaviour:
- What changed:

### Example where controls hurt
- Prompt ID:
- Why it hurt:
- Proposed fix:
